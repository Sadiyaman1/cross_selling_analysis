# -*- coding: utf-8 -*-
"""ECommerce_Dataprep_EDA

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/embedded/projects/ecommerce-petshop-costopt/locations/europe-west3/repositories/015dae9f-d880-4d26-81cb-6629c21eec5c

# ðŸŸ¦ **Cross-Selling Analyis - Data Preparation and EDA for E-Commerce Pet Shop**  
### Focus: Cross-Selling Analysis  

In this notebook, we will prepare the dataset and perform **Exploratory Data Analysis (EDA)**.  
The main objective is to clean the data, create **fact & dimension tables**, and calculate key metrics for **cross-selling opportunities**.  

---

**<u>Raw Dataset:</u>**  

We will work with three main tables:  

**Sales Table**  
Contains information about each sale, the customer, and the product.  
- Transaction Date  
- Customer ID  
- Description  
- Stock Code  
- Invoice No  
- Quantity  
- Sales  
- Unit Price  

**State Mapping Table**  
Maps different state code variations to a standardized format.  
- Order State  
- State  
- Region  

**Product Table**  
Contains product attributes and cost details.  
- Stock Code  
- Weight  
- Landed Cost  
- Shipping Cost (1000 miles)  
- Description  
- Category  

---

### **Scenario**  
The **Marketing Department** requested an analysis to identify product pairs that are frequently purchased together.  
The goal is to align cross-selling strategies with the companyâ€™s objectives:  
- Increase **sales** through bundle promotions  
- Maximize **profit** by focusing on high-margin combinations  
- Improve **customer experience** by recommending meaningful product pairs  
- Support **data-driven merchandising** and **commercial decision-making**  

---

### **Data Layers in this Project**  

## 1. **Staging Layer**  
  - Load CSVs into Cloud Storage & BigQuery  
  - Create raw tables  
  - Perform uniqueness checks  
  - Trim & standardize columns  
  - No cleaning yet (only preparation)  
---

## 2. **Intermediate Layer**  
- The data is cleaned and standardized across all tables.  
- Missing values are handled and documented.  
- Datatypes for join keys are standardized.  
- Range checks are performed for numerical columns (e.g. quantity > 0, sales > 0, unit_price > 0).  
- Final step: all tables are **joined together** to create a consolidated dataset.  

Purpose: Provide a **clean, consistent, and validated dataset** for downstream analytics.  

---

## 3. **Datamart Layer**  

This is the **business-ready dataset** for the **cross-selling use case**.  

**Final Main Table**   
- Metrics created:  
  - Number of transactions containing cross-selling activity
  - Average cross-selling price
  - Revenue generated from cross-selling combinations
  - Profit generated from cross-selling combinations
  - Profit margin from cross-selling transactions
  - Cross-selling rate (share of transactions with paired purchases)
  - Support (how often a product/product pair appears in transactions)
  - Confidence (likelihood that B is purchased when A is bought)
  - Lift (strength of the Aâ†’B relationship beyond chance)  
- Level: **transaction_quarter + product pair**  

**CSR Table**
- Cross-selling rate aggregated at **quarter level**.  
- Metrics created:  
  - Number of transactions containing cross-selling activity  
  - Total number of transactions  
  - Cross-selling rate (share of transactions with cross-selling behaviour)  
  - Trend behaviour over time (quarter-to-quarter change)  
- Level: **transaction_quarter**  

**Purpose:** Give the marketing team **clear KPIs** to identify strong product pairs and decide where to invest.  

---

## 4. **Exploratory Data Analysis (EDA) with Python**  

After creating the **Data Mart**, we perform a final **EDA** in Python.  

Goals:  
- Validate that **cross-selling metrics** behave as expected
- Check for outliers and unexpected patterns.  
- Build a **dashboard-ready dataset**.  

---

## 5. **Dashboard**  
The prepared metrics and dimensions are visualized in a dashboard.  
Focus:  
- Sales, Profit, Margin, Price  
- Cross-Selling Rate, Support, Confidence & Lift  
- Quarterly Trends  

---

**Pitch version (1-Sentence):**  
*This project identifies profitable cross-selling opportunities by analyzing product pairs and their quarterly trends, enabling the marketing team to design data-driven campaigns.*

# ðŸŸ¦ **1. Staging Layer**

## ðŸ”µ **Step 1: Extract and Load**

### ðŸ”¹**1. CSVs from Notebook â†’ Cloud Storage**
"""

# 1. CSVs from Notebook â†’ Cloud Storage

from google.cloud import storage

# Define your GCS bucket
bucket_name = "ecommerce_petshop_raw_data"

# Local files (already in Notebook root)
local_files = {
    "/customers.csv": "raw/customers.csv",
    "/products.csv": "raw/products.csv",
    "/sales.csv": "raw/sales.csv",
    "/state_region_mapping.csv": "raw/state_region_mapping.csv"
}

# Initialize GCS client
client = storage.Client()
bucket = client.bucket(bucket_name)

# Loop through all local â†’ cloud file pairs
for local_path, gcs_path in local_files.items():

    # Create a blob (file object) in the bucket at gcs_path
    # Blob = single file inside a GCS bucket
    blob = bucket.blob(gcs_path)

    # Upload the local file into this blob (cloud file)
    blob.upload_from_filename(local_path)

    # Print confirmation: local â†’ cloud
    print(f"âœ… Uploaded {local_path} â†’ gs://{bucket_name}/{gcs_path}")

"""### ðŸ”¹ **2. Creating all tables**"""

# Commented out IPython magic to ensure Python compatibility.
# # 2. Creating all tables
# 
# %%bigquery
# -- 2.1 creating customers table
# CREATE OR REPLACE TABLE `ecommerce-petshop-costopt.ecommerce_petshop.customers` (
#   customer_id STRING,
#   order_city STRING,
#   order_postal STRING,
#   order_state STRING,
#   latitude FLOAT64,
#   longitude FLOAT64
# )
# OPTIONS(description = "raw customers data");
# 
# -- 2.2 creating products table
# CREATE OR REPLACE TABLE `ecommerce-petshop-costopt.ecommerce_petshop.products` (
#   stock_code STRING,
#   weight FLOAT64,
#   landed_cost FLOAT64,
#   shipping_cost_1000_mile FLOAT64,
#   description STRING,
#   category STRING
# )
# OPTIONS(description = "raw products data");
# 
# -- 2.3 creating sales table
# CREATE OR REPLACE TABLE `ecommerce-petshop-costopt.ecommerce_petshop.sales` (
#   transaction_date STRING,
#   customer_id INT64,
#   description STRING,
#   stock_code STRING,
#   invoice_no INT64,
#   quantity INT64,
#   sales FLOAT64,
#   unit_price FLOAT64
# )
# OPTIONS(description = "raw sales data");
# 
# -- 2.4 creating state-region mapping table
# CREATE OR REPLACE TABLE `ecommerce-petshop-costopt.ecommerce_petshop.state_region_mapping` (
#   string_field_0 STRING,
#   string_field_1 STRING,
#   string_field_2 STRING
# )
# OPTIONS(description = "raw state-region mapping data");
#

"""### ðŸ”¹ **3. Load CSV Data from GCS**


"""

# Commented out IPython magic to ensure Python compatibility.
# # 3.1  Load CSV Data from GCS â†’ Raw customers Table
# 
# %%bigquery
# LOAD DATA INTO `ecommerce-petshop-costopt.ecommerce_petshop.customers`
# FROM FILES (
#   format = 'CSV',
#   uris = ['gs://ecommerce_petshop_raw_data/raw/customers.csv'],
#   skip_leading_rows = 1,
#   field_delimiter = ',',
#   quote = '"'
# );
#

# Commented out IPython magic to ensure Python compatibility.
# # 3.2  Load CSV Data from GCS â†’ Raw products Table
# 
# %%bigquery
# LOAD DATA INTO `ecommerce-petshop-costopt.ecommerce_petshop.products`
# FROM FILES (
#     format = 'CSV',
#     uris = ['gs://ecommerce_petshop_raw_data/raw/products.csv'],
#     skip_leading_rows = 1,
#     field_delimiter = ',',
#     quote = '"'
# );

# Commented out IPython magic to ensure Python compatibility.
# # 3.3  Load CSV Data from GCS â†’ Raw sales Table
# 
# %%bigquery
# LOAD DATA INTO `ecommerce-petshop-costopt.ecommerce_petshop.sales`
# FROM FILES (
#     format = 'CSV',
#     uris = ['gs://ecommerce_petshop_raw_data/raw/sales.csv'],
#     skip_leading_rows = 1,
#     field_delimiter = ',',
#     quote = '"'
# );

# Commented out IPython magic to ensure Python compatibility.
# # 3.4  Load CSV Data from GCS â†’ Raw state_region_mapping Table
# 
# %%bigquery
# LOAD DATA INTO `ecommerce-petshop-costopt.ecommerce_petshop.state_region_mapping`
# FROM FILES (
#   format = 'CSV',
#   uris = ['gs://ecommerce_petshop_raw_data/raw/state_region_mapping.csv'],
#   skip_leading_rows = 1,
#   field_delimiter = ',',
#   quote = '"'
# );
#

"""### ðŸ”¹ **4. First View of Data Tables**"""

# Commented out IPython magic to ensure Python compatibility.
# # 4.1 customers table
# 
# %%bigquery
# SELECT *
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.customers`
# LIMIT 100;

# Commented out IPython magic to ensure Python compatibility.
# # 4.2 products table
# 
# %%bigquery
# SELECT *
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.products`
# LIMIT 100;

# Commented out IPython magic to ensure Python compatibility.
# # 4.3 sales table
# 
# %%bigquery
# SELECT *
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.sales`
# LIMIT 100;

# Commented out IPython magic to ensure Python compatibility.
# # 4.4 state_region_mapping table
# 
# %%bigquery
# SELECT *
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.state_region_mapping`
# LIMIT 100;

"""## ðŸ”µ **Step 2 Uniqueness Checks**

Before we start the analysis, it is important to check if the main key columns  
(customer IDs, product codes, invoice numbers, etc.) are unique.  
This helps us to find possible data quality issues such as duplicates.

We will perform the following checks:

- **Customer ID** in the `customers` table  
- **Stock Code** in the `products` table  
- **Invoice No** in the `sales` table  
- **Transaction Date** in the `sales` table  
- **Order State** in the `state_region_mapping` table  

These checks show us if any of these fields have duplicate values.  
Duplicates can signal data entry errors or cases where the same key appears more than once.

"""

# Commented out IPython magic to ensure Python compatibility.
# # Step_2 customer_id in customers table
# 
# %%bigquery
# SELECT customer_id, COUNT(*) AS key_count
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.customers`
# GROUP BY customer_id
# HAVING COUNT(*) > 1
# LIMIT 10;

# Commented out IPython magic to ensure Python compatibility.
# # Step_2 stock_code in products table
# 
# %%bigquery
# SELECT stock_code, COUNT(*) AS key_count
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.products`
# GROUP BY stock_code
# HAVING COUNT(*) > 1
# LIMIT 10;

# Commented out IPython magic to ensure Python compatibility.
# # Step_2 invoice_no in sales table
# 
# %%bigquery
# SELECT invoice_no, COUNT(*) AS key_count
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.sales`
# GROUP BY invoice_no
# HAVING COUNT(*) > 1
# LIMIT 10;

# Commented out IPython magic to ensure Python compatibility.
# # Step_2 transaction_date in sales table
# 
# %%bigquery
# SELECT transaction_date, COUNT(*) AS key_count
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.sales`
# GROUP BY transaction_date
# HAVING COUNT(*) > 1
# LIMIT 10;

# Commented out IPython magic to ensure Python compatibility.
# # Step_2 (transaction_date + invoice_no + stock_code) in sales table
# 
# %%bigquery
# SELECT transaction_date, invoice_no, stock_code, COUNT(*) AS key_count
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.sales`
# GROUP BY transaction_date, invoice_no, stock_code
# HAVING COUNT(*) > 1
# LIMIT 10;

# Commented out IPython magic to ensure Python compatibility.
# # Step_2 order_state in state_region_mapping table
# 
# %%bigquery
# SELECT string_field_1 AS order_state, COUNT(*) AS key_count
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.state_region_mapping`
# GROUP BY order_state
# HAVING COUNT(*) > 1
# ORDER BY order_state;
# 
#

"""### ðŸ”¹ **Result Step 2**

- **`customer_id`** â†’ Unique  
- **`stock_code`** â†’ Unique
- **`order_state`** â†’ No unique key
- **`sales table`** â†’ No unique key

This means the sales table has no single column that uniquely identifies each row.  
Without a primary key, we cannot guarantee data integrity and it becomes difficult to  
manage duplicates or safely connect the table with others.

---
**Action**

**1. Add a Primary Key to sales table**

We will add a new column called `order_line_item` as a **Primary Key**.  
This column will be created with `GENERATE_UUID()`, so that every row gets a unique identifier.  
It does not change the existing data, but simply provides a reliable unique key for the sales table.

**2. Transform state column to Primary Key in state_region_mapping table**

we will solve that later with **Step 3(Staging): Trim and Standardize Columns** and **STEP 1(intermediate) â€“ Standardization across tables**

**Why we do this:**  
- Ensure that every row has a unique identifier  
- Prevent problems with duplicate rows  
- Allow safer joins with other tables  
- Improve data quality and consistency for future analysis  

"""

# Commented out IPython magic to ensure Python compatibility.
# # Step_2 ADD Primary KEY to sales table
# 
# %%bigquery
# ALTER TABLE `ecommerce-petshop-costopt.ecommerce_petshop.sales`
# ADD COLUMN order_line_item STRING;
# 
# UPDATE `ecommerce-petshop-costopt.ecommerce_petshop.sales`
# SET order_line_item = GENERATE_UUID()
# WHERE order_line_item IS NULL;
# 
# 
#

# Commented out IPython magic to ensure Python compatibility.
# 
# %%bigquery
# SELECT*
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.sales`
# LIMIT 50;
#

"""## ðŸ”µ **Step 3: Trim and Standardize Columns**

In this step we clean and standardize the raw tables.  
The goal is to remove extra spaces, fix text casing, and make all key fields consistent across tables.  

We apply the following transformations:

- **Customers table**  
  - Trim spaces from `customer_id`, `order_city`, and `order_postal`  
  - Convert city names to proper case (e.g., "new york" â†’ "New York")  
  - Clean `order_state`: remove dots and extra spaces, and convert to 2-letter uppercase state codes  

- **Products table**  
  - Trim spaces from `stock_code` and `description`  
  - Convert product categories to proper case (e.g., "pet food" â†’ "Pet Food")  
  - **Cast numeric fields (`weight`, `landed_cost`, `shipping_cost_1000_mile`) into `NUMERIC`**  
    â†’ to avoid floating-point rounding mistakes in later cost and margin calculations  

- **Sales table**  
  - Parse and normalize `transaction_date` into proper DATE format  
  - Trim spaces from `transaction_date`, `description`, `stock_code`  
  - **Cast numeric fields (`quantity`, `sales`, `unit_price`) into `NUMERIC`**  
    â†’ because we will perform many aggregations (sums, averages, weighted averages, ratios) later,  
      and `NUMERIC` ensures accuracy compared to `FLOAT64`  

- **State Region Mapping table**  
  - Standardize `order_state` into proper case (e.g., "new york" â†’ "New York")  
  - Clean `state`: remove dots and extra spaces, and convert to uppercase 2-letter codes  
  - Normalize `region` names by trimming spaces and converting to proper case  

>This step ensures that all identifiers, categorical fields, and numeric measures are **clean and standardized**,  
which prevents duplicates and avoids rounding errors during later confidence/lift calculations.

"""

# Commented out IPython magic to ensure Python compatibility.
# # STEP_3 customers table
# %%bigquery
# CREATE OR REPLACE VIEW `ecommerce-petshop-costopt.ecommerce_petshop.stage_step3_cust` AS
# SELECT TRIM(customer_id) AS customer_id,
# 			 INITCAP(LOWER(TRIM(order_city))) AS order_city,
#        TRIM(order_postal) AS order_postal,
# 			 TRIM(UPPER(REGEXP_REPLACE(REGEXP_REPLACE(order_state, r'\.', ''), r'\s+', ' '))) AS state_initials,
#   		 latitude,
#        longitude
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.customers`;

# Commented out IPython magic to ensure Python compatibility.
# # STEP_2 products table
# 
# %%bigquery
# CREATE OR REPLACE VIEW `ecommerce-petshop-costopt.ecommerce_petshop.stage_step3_prod` AS
# SELECT
#     TRIM(stock_code) AS stock_code,
#     weight AS weight,
#     landed_cost AS landed_cost,
#     shipping_cost_1000_mile AS shipping_cost_1000_mile,
#     TRIM(description) AS description,
#     INITCAP(LOWER(TRIM(category))) AS category
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.products`;
#

# Commented out IPython magic to ensure Python compatibility.
# # STEP_2 sales table
# 
# %%bigquery
# CREATE OR REPLACE VIEW `ecommerce-petshop-costopt.ecommerce_petshop.stage_step3_sales` AS
# SELECT
#     order_line_item,
#     DATE(
#         COALESCE(
#             SAFE.PARSE_DATETIME('%Y-%m-%d %H:%M:%S', transaction_date),
#             SAFE.PARSE_DATETIME('%Y-%m-%d %H:%M',     transaction_date),
#             SAFE.PARSE_DATETIME('%Y-%m-%d',           transaction_date),
#             SAFE.PARSE_DATETIME('%m/%d/%Y %H:%M:%S',  transaction_date),
#             SAFE.PARSE_DATETIME('%m/%d/%Y %H:%M',     transaction_date),
#             SAFE.PARSE_DATETIME('%m/%d/%Y',           transaction_date)
#         )
#     ) AS transaction_date,
#     customer_id,
#     TRIM(description) AS description,
#     TRIM(stock_code) AS stock_code,
#     invoice_no,
#     quantity AS quantity,
#     sales AS sales,
#     unit_price AS unit_price
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.sales`;
#

# Commented out IPython magic to ensure Python compatibility.
# # STEP_2 state_region_mapping table
# 
# %%bigquery
# CREATE OR REPLACE VIEW `ecommerce-petshop-costopt.ecommerce_petshop.stage_step_3_state` AS
# SELECT INITCAP(TRIM(LOWER(string_field_1))) AS state_name,
# 			 TRIM(UPPER(REGEXP_REPLACE(REGEXP_REPLACE(string_field_0, r'\.', ''), r'\s+', ' '))) AS state_initials, # 1. remove leading/trailing spaces; 2. convert everything to uppercase; 3. remove dots (e.g., "N.Y." â†’ "NY"); 4. replace multiple spaces with a single space
#        INITCAP(REGEXP_REPLACE(TRIM(LOWER(string_field_2)), '\\s+', ' ')) AS region # 1. lowercase + trim spaces; 2. normalize spacing; 3. capitalize first letter of each word
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.state_region_mapping`;
# 
#

"""# ðŸŸ¦ **2. Intermediate Layer**

## ðŸ”µ **STEP 1 â€“ Standardization across tables**

1. **State Region Mapping table**  
   - Convert each `state_initials` value (two-letter code) into its **full state name**.    

2. **Customers table**  
   - Transform each `state_initials` value into **two-letter state codes**.  
   - Ensure uniform state representation for all customers.  

3. **Products table**  
   - Normalize the `category` column by grouping all values containing `"Food"` into a single category called **food**.  

This step makes sure state and category information is consistent across datasets, which simplifies later joins and analysis.
"""

# Commented out IPython magic to ensure Python compatibility.
# # STEP_1 - 1. state_region_mapping table (identify issues)
# %%bigquery
# SELECT *
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.stage_step_3_state`
# LIMIT 1000;
#

# Commented out IPython magic to ensure Python compatibility.
# # STEP_1 - 1. state_region_mapping table
# 
# %%bigquery
# CREATE OR REPLACE VIEW `ecommerce-petshop-costopt.ecommerce_petshop.inter_step1_state` AS
# SELECT DISTINCT
#    state_initials,
#    CASE state_initials
#         WHEN 'AE'  THEN 'Armed Forces (Europe)'
#         WHEN 'AK'  THEN 'Alaska'
#         WHEN 'AL'  THEN 'Alabama'
#         WHEN 'AR'  THEN 'Arkansas'
#         WHEN 'AZ'  THEN 'Arizona'
#         WHEN 'CA'  THEN 'California'
#         WHEN 'CO'  THEN 'Colorado'
#         WHEN 'CT'  THEN 'Connecticut'
#         WHEN 'DC'  THEN 'District of Columbia'
#         WHEN 'DE'  THEN 'Delaware'
#         WHEN 'FL'  THEN 'Florida'
#         WHEN 'GA'  THEN 'Georgia'
#         WHEN 'HI'  THEN 'Hawaii'
#         WHEN 'IA'  THEN 'Iowa'
#         WHEN 'ID'  THEN 'Idaho'
#         WHEN 'IL'  THEN 'Illinois'
#         WHEN 'IN'  THEN 'Indiana'
#         WHEN 'KS'  THEN 'Kansas'
#         WHEN 'KY'  THEN 'Kentucky'
#         WHEN 'LA'  THEN 'Louisiana'
#         WHEN 'MA'  THEN 'Massachusetts'
#         WHEN 'MD'  THEN 'Maryland'
#         WHEN 'ME'  THEN 'Maine'
#         WHEN 'MI'  THEN 'Michigan'
#         WHEN 'MN'  THEN 'Minnesota'
#         WHEN 'MO'  THEN 'Missouri'
#         WHEN 'MS'  THEN 'Mississippi'
#         WHEN 'MT'  THEN 'Montana'
#         WHEN 'NC'  THEN 'North Carolina'
#         WHEN 'ND'  THEN 'North Dakota'
#         WHEN 'NE'  THEN 'Nebraska'
#         WHEN 'NH'  THEN 'New Hampshire'
#         WHEN 'NJ'  THEN 'New Jersey'
#         WHEN 'NM'  THEN 'New Mexico'
#         WHEN 'NV'  THEN 'Nevada'
#         WHEN 'NY'  THEN 'New York'
#         WHEN 'OH'  THEN 'Ohio'
#         WHEN 'OK'  THEN 'Oklahoma'
#         WHEN 'OR'  THEN 'Oregon'
#         WHEN 'PA'  THEN 'Pennsylvania'
#         WHEN 'RI'  THEN 'Rhode Island'
#         WHEN 'SC'  THEN 'South Carolina'
#         WHEN 'SD'  THEN 'South Dakota'
#         WHEN 'TN'  THEN 'Tennessee'
#         WHEN 'TX'  THEN 'Texas'
#         WHEN 'UT'  THEN 'Utah'
#         WHEN 'VT'  THEN 'Vermont'
#         WHEN 'VA'  THEN 'Virginia'
#         WHEN 'WA'  THEN 'Washington'
#         WHEN 'WI'  THEN 'Wisconsin'
#         WHEN 'WV'  THEN 'West Virginia'
#         WHEN 'WY'  THEN 'Wyoming'
#         WHEN 'PR'  THEN 'Puerto Rico'
#         WHEN 'USVI'  THEN 'U.S. Virgin Islands'
#         ELSE state_name   -- if there is no match
#    END AS state_name,
#    CASE state_initials
#    			WHEN 'TN' THEN 'Central'
#         ELSE region
#    END AS region
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.stage_step_3_state`;

"""### ðŸ”¹ **Result Step 1**

Now we have created a **unique key** for the `state_region_mapping` table.  
This was already mentioned back in **Step 3(Staging Layer) â€“ Checking Uniqueness**, where we found that the column `state_initials` was not unique enough on its own.  
We solved this issue during  by:  
- Trimming and standardizing the column values,  
- Mapping each state abbreviation (`state_initials`) to a **full state name** and a **region**.  

**Result:**  
- The column `state_initials` can now safely serve as a **primary key** for the mapping table.  
- This allows us to reliably join with the **customer table** and connect states to regions without ambiguity.  
- Data quality and consistency are improved for future analysis.  

"""

# Commented out IPython magic to ensure Python compatibility.
# # Perform uniqueness check from Step 1
# 
# %%bigquery
# SELECT state_initials, COUNT(*) AS key_count
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step1_state`
# GROUP BY state_initials
# HAVING COUNT(*) > 1
# LIMIT 10

"""**Result:**

- `state_initials` column in `state_region_mapping` table is unique.
"""

# Commented out IPython magic to ensure Python compatibility.
# # STEP_1 - 2.customers table (identify issues)
# %%bigquery
# SELECT *
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.stage_step3_cust`
# LIMIT 1000;

# Commented out IPython magic to ensure Python compatibility.
# # STEP_1 - 2.customers table
# 
# %%bigquery
# CREATE OR REPLACE VIEW `ecommerce-petshop-costopt.ecommerce_petshop.inter_step1_cust` AS
# SELECT
# 	 customer_id,
#    order_city,
#    order_postal,
#    CASE state_initials
#         WHEN 'ARMED FORCES (EUROPE)' THEN 'AE'
#         WHEN 'ALASKA'                THEN 'AK'
#         WHEN 'ALABAMA'               THEN 'AL'
#         WHEN 'ARKANSAS'              THEN 'AR'
#         WHEN 'ARIZONA'               THEN 'AZ'
#         WHEN 'CALIFORNIA'            THEN 'CA'
#         WHEN 'COLORADO'              THEN 'CO'
#         WHEN 'CONNECTICUT'           THEN 'CT'
#         WHEN 'DISTRICT OF COLUMBIA'  THEN 'DC'
#         WHEN 'DELAWARE'              THEN 'DE'
#         WHEN 'FLORIDA'               THEN 'FL'
#         WHEN 'GEORGIA'               THEN 'GA'
#         WHEN 'HAWAII'                THEN 'HI'
#         WHEN 'IOWA'                  THEN 'IA'
#         WHEN 'IDAHO'                 THEN 'ID'
#         WHEN 'ILLINOIS'              THEN 'IL'
#         WHEN 'INDIANA'               THEN 'IN'
#         WHEN 'KANSAS'                THEN 'KS'
#         WHEN 'KENTUCKY'              THEN 'KY'
#         WHEN 'LOUISIANA'             THEN 'LA'
#         WHEN 'MASSACHUSETTS'         THEN 'MA'
#         WHEN 'MARYLAND'              THEN 'MD'
#         WHEN 'MAINE'                 THEN 'ME'
#         WHEN 'MICHIGAN'              THEN 'MI'
#         WHEN 'MINNESOTA'             THEN 'MN'
#         WHEN 'MISSOURI'              THEN 'MO'
#         WHEN 'MISSISSIPPI'           THEN 'MS'
#         WHEN 'MONTANA'               THEN 'MT'
#         WHEN 'NORTH CAROLINA'        THEN 'NC'
#         WHEN 'NORTH DAKOTA'          THEN 'ND'
#         WHEN 'NEBRASKA'              THEN 'NE'
#         WHEN 'NEW HAMPSHIRE'         THEN 'NH'
#         WHEN 'NEW JERSEY'            THEN 'NJ'
#         WHEN 'NEW MEXICO'            THEN 'NM'
#         WHEN 'NEVADA'                THEN 'NV'
#         WHEN 'NEW YORK'              THEN 'NY'
#         WHEN 'OHIO'                  THEN 'OH'
#         WHEN 'OKLAHOMA'              THEN 'OK'
#         WHEN 'OREGON'                THEN 'OR'
#         WHEN 'PENNSYLVANIA'          THEN 'PA'
#         WHEN 'PUERTO RICO'           THEN 'PR'
#         WHEN 'RHODE ISLAND'          THEN 'RI'
#         WHEN 'SOUTH CAROLINA'        THEN 'SC'
#         WHEN 'SOUTH DAKOTA'          THEN 'SD'
#         WHEN 'TENNESSEE'             THEN 'TN'
#         WHEN 'TEXAS'                 THEN 'TX'
#         WHEN 'UTAH'                  THEN 'UT'
#         WHEN 'VERMONT'               THEN 'VT'
#         WHEN 'VIRGINIA'              THEN 'VA'
#         WHEN 'WASHINGTON'            THEN 'WA'
#         WHEN 'WISCONSIN'             THEN 'WI'
#         WHEN 'WEST VIRGINIA'         THEN 'WV'
#         WHEN 'WYOMING'               THEN 'WY'
#         WHEN 'PUERTO RICO'           THEN 'PR'
#         WHEN 'U.S. VIRGIN ISLANDS'   THEN 'VI'
#         ELSE state_initials   -- if there is no match
#    END AS state_initials,
#    latitude,
#    longitude
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.stage_step3_cust`;

# Commented out IPython magic to ensure Python compatibility.
# # STEP_1 - 3.products table
# 
# %%bigquery
# CREATE OR REPLACE VIEW `ecommerce-petshop-costopt.ecommerce_petshop.inter_step1_prod` AS
# SELECT
# 			 stock_code,
#        weight,
#        landed_cost,
#        shipping_cost_1000_mile,
#        description,
#        CASE
#        		WHEN LOWER(category) LIKE '%food%' THEN 'Food'
#           ELSE category
#        END AS category
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.stage_step3_prod`;

"""## ðŸ”µ **STEP 2 â€“ Handling Missing Values**  

In this step, we check all tables for missing values:  

- `products`
- `state_region_mapping`   
- `customers`
- `sales`  

"""

# Commented out IPython magic to ensure Python compatibility.
# # STEP_2 - products table
# %%bigquery
# SELECT * FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step1_prod`
# WHERE stock_code IS NULL
#    OR weight IS NULL
#    OR landed_cost IS NULL
#    OR shipping_cost_1000_mile IS NULL
#    OR description IS NULL
#    OR category IS NULL;
#

"""**Result**

No missing values.  
"""

# Commented out IPython magic to ensure Python compatibility.
# # STEP_2 - state_region_mapping table
# %%bigquery
# SELECT * FROM ecommerce-petshop-costopt.ecommerce_petshop.inter_step1_state
# WHERE state_initials IS NULL
#   OR state_name IS NULL
#   OR region IS NULL;

"""**Result**

No missing values.  
"""

# Commented out IPython magic to ensure Python compatibility.
# # STEP_2 - customers table
# %%bigquery
# SELECT *
# FROM ecommerce-petshop-costopt.ecommerce_petshop.inter_step1_cust
# WHERE customer_id IS NULL
#    OR order_city IS NULL
#    OR order_postal IS NULL
#    OR state_initials IS NULL
#    OR latitude IS NULL
#    OR longitude IS NULL;
#

"""**Result**

The only missing values are in the **latitude** and **longitude** columns.  

**Action**

We could enrich the data by fetching geolocation details via an external API.  

- If we visualize the data in **Tableau**, we can rely on its built-in **geocoding** features. Tableau can automatically convert country, state, city, postal code, and even street-level addresses into map points.  

- If we visualize the data in **Looker (or Looker Studio)**, we rely on its built-in **Google Maps integration** to display geographic fields such as country, state, region, city, or postal code.  
  Unlike Tableau, Looker does **not perform full geocoding on its own** â€” it cannot convert a full address into latitude/longitude coordinates.

Therefore, no further action will be taken here, since both tools can display our data on maps, but in different ways.  
For our analysis, geographic coordinates are not required, so we will not introduce an external geocoding API for the Looker dashboard.
"""

# Commented out IPython magic to ensure Python compatibility.
# # STEP_2 - sales table
# %%bigquery
# SELECT * FROM `ecommerce-petshop-costopt.ecommerce_petshop.stage_step3_sales`
# WHERE order_line_item IS NULL
#   OR customer_id IS NULL
#   OR description IS NULL
#   OR stock_code IS NULL
#   OR invoice_no IS NULL
#   OR quantity IS NULL
#   OR sales IS NULL
#   OR unit_price IS NULL;
# 
#

"""### ðŸ”¹ **Data Cleaning Decisions**

1. **Customer ID**  
   - **Result:** Missing in some rows  
   - **Action:** Check if each `invoice_no` always belongs to one customer.  
     - If yes â†’ fill missing `customer_id` using that `invoice_no`.  
     - If not â†’ keep as NULL.  

2. **Invoice No**  
   - **Result:** Missing in some rows  
   - **Action:** Could try filling from `customer_id`.  
     - But one customer can have many invoices â†’ not safe.  
     - Decision: keep as NULL.  

3. **Quantity, Sales, Unit Price**  
   - **Result:** Some values are missing  
   - **Action:**  
     - If at least two of these are present â†’ calculate the missing one using `Sales = Quantity * Unit Price`.  
     - If fewer than two are present â†’ set missing value to **0**.  

4. **Description**  
   - **Result:** Missing in some rows  
   - **Action:** Will be fixed later in **Step 5 (Joining tables)**,  
     because the product table has full descriptions.  

5. **Transaction Date**  
   - **Result:** Missing in some rows  
   - **Action:** Cannot be inferred reliably.  
     - Decision: keep as NULL.  

6. **Stock Code**  
   - **Result:** Missing in some rows  
   - **Action:** Will be fixed later in **Step 5 (Joining tables)**.  
     We will use a **COALESCE join** on `stock_code` and `description`:  
       - If `stock_code` is missing in the sales table but a matching `description` exists in the product table,  
         the `stock_code` will be filled from the product table.  
       - If **both `stock_code` and `description` are missing**, we have no way to recover the product information.  
         These rows will be filtered out later using a `NOT NULL` condition on `stock_code`.  
   - This approach ensures that valid products are preserved and only completely unusable rows are removed.  


"""

# Commented out IPython magic to ensure Python compatibility.
# # STEP_2 - sales table - (Customer ID Check)
# # Customer ID: check if every invoice_no is always linked to exactly one customer
# %%bigquery
# SELECT invoice_no, COUNT(DISTINCT customer_id) as cust_count
# FROM ecommerce-petshop-costopt.ecommerce_petshop.stage_step3_sales
# GROUP BY invoice_no
# HAVING cust_count > 1;

"""**Result â€“ Sales Table (Customer ID Check)**

- Every **invoice_no** is linked to exactly **one customer_id**.  
- The counts shown in the output only appear when both **invoice_no** is **NULL**.  

"""

# Commented out IPython magic to ensure Python compatibility.
# # STEP_2 - sales table
# # Customer ID:   small example before filling values
# %%bigquery
# SELECT customer_id, invoice_no
# FROM ecommerce-petshop-costopt.ecommerce_petshop.stage_step3_sales AS a
# WHERE invoice_no = 581476;

# Commented out IPython magic to ensure Python compatibility.
# # STEP_2 - sales table
# # Customer ID: same example after filling values
# 
# %%bigquery
# SELECT
#     invoice_no,
#     COALESCE(customer_id, MAX(customer_id) OVER (PARTITION BY invoice_no)) AS customer_id
# FROM ecommerce-petshop-costopt.ecommerce_petshop.stage_step3_sales
# WHERE invoice_no = 581476;
# 
#

"""**Result** â€” Filling Customer IDs

- Before: Some rows had `customer_id = NULL` even though the same `invoice_no`
  had a valid customer in another row.
- After: All rows for the same `invoice_no` now share the correct `customer_id`.

**Action**
We can now apply this logic to the **entire sales table**
to fill missing customer IDs while keeping all rows unchanged.

"""

# Commented out IPython magic to ensure Python compatibility.
# # STEP_2 - sales table
# # Customer ID: filling all values, where possible
# # Quantity, Sales, Unit Price: filling all values, where possible
# 
# %%bigquery
# CREATE OR REPLACE VIEW `ecommerce-petshop-costopt.ecommerce_petshop.inter_step2_sales` AS
# SELECT order_line_item,
#     	 transaction_date,
#        COALESCE(customer_id, MAX(customer_id) OVER (PARTITION BY invoice_no)) AS customer_id,
#        description,
#        stock_code,
#        invoice_no,
#        CASE WHEN quantity IS NULL THEN SAFE_DIVIDE(sales, unit_price) ELSE quantity END AS quantity,
#        CASE WHEN sales IS NULL THEN quantity*unit_price ELSE sales END AS sales,
#        CASE WHEN unit_price IS NULL THEN SAFE_DIVIDE(sales, quantity) ELSE unit_price END AS unit_price
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.stage_step3_sales`;

# Commented out IPython magic to ensure Python compatibility.
# # STEP_2 - sales table - comapring rows with Null before/after
# 
# %%bigquery
# SELECT COUNT(*) AS rows_null_after_stage_step3_sales,
#        (SELECT COUNT(*) FROM  `ecommerce-petshop-costopt.ecommerce_petshop.inter_step2_sales`
#                         WHERE order_line_item IS NULL
#                         OR customer_id IS NULL
#                         OR invoice_no IS NULL
#                         OR quantity IS NULL
#                         OR sales IS NULL
#                         OR unit_price IS NULL) AS rows_nul_after_inter_step2_sales
# 
# FROM  `ecommerce-petshop-costopt.ecommerce_petshop.stage_step3_sales`
# WHERE order_line_item IS NULL
#   OR customer_id IS NULL
#   OR invoice_no IS NULL
#   OR quantity IS NULL
#   OR sales IS NULL
#   OR unit_price IS NULL;

"""**Result â€” Null value comparison**

- Before Step 3: 10678 rows had at least one NULL value.  
- After Step 3:  7782 rows had at least one NULL value.  

**Effect**
- 2896 rows were fixed.  
- Missing values were reduced in multiple columns:
  - **Customer ID** (filled using other rows with same invoice_no)  
  - **Quantity, Sales, Unit Price** (calculated when possible)  

**Outcome**
Data quality improved significantly.  
We successfully filled thousands of missing values while keeping all original rows.

## ðŸ”µ **Step 3 â€“ Standardizing Datatypes for Join Keys**

We convert `customer_id` and `invoice_no` into **STRING** format.  
This ensures that all tables use the same datatype for join keys and avoids mismatches during joins.
"""

# Commented out IPython magic to ensure Python compatibility.
# # Step 3 â€“ Standardizing Datatypes for Join Keys
# 
# %%bigquery
# CREATE OR REPLACE VIEW `ecommerce-petshop-costopt.ecommerce_petshop.inter_step3_sales` AS
# SELECT order_line_item,
#        transaction_date,
#        SAFE_CAST(customer_id AS STRING) AS customer_id,
#        description,
#        stock_code,
#        SAFE_CAST(invoice_no AS STRING) AS invoice_no,
#        quantity,
#        sales,
#        unit_price
# FROM  `ecommerce-petshop-costopt.ecommerce_petshop.stage_step3_sales`;

"""## ðŸ”µ **Step 4 â€“ Range Chekcs for numerical columns**"""

# Commented out IPython magic to ensure Python compatibility.
# # STEP_4 - sales table - checking for metric ranges
# 
# %%bigquery
# SELECT *
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step3_sales`
# WHERE sales <= 0 OR quantity <= 0 OR unit_price <=0

"""**Result**

At first sight, we can already see implausible data, for example cases where  
- **sales < 0** or  
- **quantity = 0**.  

This means we need to investigate more carefully.  

**Action**

To structure our investigation, we split the **sales table** into all possible cases.  
We look at **3 states** for each of the **3 columns** (`quantity`, `sales`, `unit_price`).  
That gives us **3Â³ = 27 possible cases**:  

1. quantity < 0, sales < 0, unit_price < 0  
2. quantity < 0, sales < 0, unit_price = 0  
3. quantity < 0, sales < 0, unit_price > 0  
4. quantity < 0, sales = 0, unit_price < 0  
5. quantity < 0, sales = 0, unit_price = 0  
6. quantity < 0, sales = 0, unit_price > 0  
7. quantity < 0, sales > 0, unit_price < 0  
8. quantity < 0, sales > 0, unit_price = 0  
9. quantity < 0, sales > 0, unit_price > 0  

10. quantity = 0, sales < 0, unit_price < 0  
11. quantity = 0, sales < 0, unit_price = 0  
12. quantity = 0, sales < 0, unit_price > 0  
13. quantity = 0, sales = 0, unit_price < 0  
14. quantity = 0, sales = 0, unit_price = 0  
15. quantity = 0, sales = 0, unit_price > 0  
16. quantity = 0, sales > 0, unit_price < 0  
17. quantity = 0, sales > 0, unit_price = 0  
18. quantity = 0, sales > 0, unit_price > 0  

19. quantity > 0, sales < 0, unit_price < 0  
20. quantity > 0, sales < 0, unit_price = 0  
21. quantity > 0, sales < 0, unit_price > 0  
22. quantity > 0, sales = 0, unit_price < 0  
23. quantity > 0, sales = 0, unit_price = 0  
24. quantity > 0, sales = 0, unit_price > 0  
25. quantity > 0, sales > 0, unit_price < 0  
26. quantity > 0, sales > 0, unit_price = 0  
27. quantity > 0, sales > 0, unit_price > 0  

In the next steps, we will check each case and try to find a **data-driven explanation**.  
If no explanation is possible from the data, then an **internal discussion with the business team** will be required.

### ðŸ”¹ **Case Flags**
"""

# Commented out IPython magic to ensure Python compatibility.
# # STEP_4 - sales table - checking for metric ranges - case flags
# 
# %%bigquery
# CREATE OR REPLACE VIEW `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_rangechek` AS
# SELECT
#   *,
#   CASE
#     WHEN quantity < 0 AND sales < 0 AND unit_price < 0 THEN 'Case 1: q<0, s<0, p<0'
#     WHEN quantity < 0 AND sales < 0 AND unit_price = 0 THEN 'Case 2: q<0, s<0, p=0'
#     WHEN quantity < 0 AND sales < 0 AND unit_price > 0 THEN 'Case 3: q<0, s<0, p>0'
#     WHEN quantity < 0 AND sales = 0 AND unit_price < 0 THEN 'Case 4: q<0, s=0, p<0'
#     WHEN quantity < 0 AND sales = 0 AND unit_price = 0 THEN 'Case 5: q<0, s=0, p=0'
#     WHEN quantity < 0 AND sales = 0 AND unit_price > 0 THEN 'Case 6: q<0, s=0, p>0'
#     WHEN quantity < 0 AND sales > 0 AND unit_price < 0 THEN 'Case 7: q<0, s>0, p<0'
#     WHEN quantity < 0 AND sales > 0 AND unit_price = 0 THEN 'Case 8: q<0, s>0, p=0'
#     WHEN quantity < 0 AND sales > 0 AND unit_price > 0 THEN 'Case 9: q<0, s>0, p>0'
# 
#     WHEN quantity = 0 AND sales < 0 AND unit_price < 0 THEN 'Case 10: q=0, s<0, p<0'
#     WHEN quantity = 0 AND sales < 0 AND unit_price = 0 THEN 'Case 11: q=0, s<0, p=0'
#     WHEN quantity = 0 AND sales < 0 AND unit_price > 0 THEN 'Case 12: q=0, s<0, p>0'
#     WHEN quantity = 0 AND sales = 0 AND unit_price < 0 THEN 'Case 13: q=0, s=0, p<0'
#     WHEN quantity = 0 AND sales = 0 AND unit_price = 0 THEN 'Case 14: q=0, s=0, p=0'
#     WHEN quantity = 0 AND sales = 0 AND unit_price > 0 THEN 'Case 15: q=0, s=0, p>0'
#     WHEN quantity = 0 AND sales > 0 AND unit_price < 0 THEN 'Case 16: q=0, s>0, p<0'
#     WHEN quantity = 0 AND sales > 0 AND unit_price = 0 THEN 'Case 17: q=0, s>0, p=0'
#     WHEN quantity = 0 AND sales > 0 AND unit_price > 0 THEN 'Case 18: q=0, s>0, p>0'
# 
#     WHEN quantity > 0 AND sales < 0 AND unit_price < 0 THEN 'Case 19: q>0, s<0, p<0'
#     WHEN quantity > 0 AND sales < 0 AND unit_price = 0 THEN 'Case 20: q>0, s<0, p=0'
#     WHEN quantity > 0 AND sales < 0 AND unit_price > 0 THEN 'Case 21: q>0, s<0, p>0'
#     WHEN quantity > 0 AND sales = 0 AND unit_price < 0 THEN 'Case 22: q>0, s=0, p<0'
#     WHEN quantity > 0 AND sales = 0 AND unit_price = 0 THEN 'Case 23: q>0, s=0, p=0'
#     WHEN quantity > 0 AND sales = 0 AND unit_price > 0 THEN 'Case 24: q>0, s=0, p>0'
#     WHEN quantity > 0 AND sales > 0 AND unit_price < 0 THEN 'Case 25: q>0, s>0, p<0'
#     WHEN quantity > 0 AND sales > 0 AND unit_price = 0 THEN 'Case 26: q>0, s>0, p=0'
#     WHEN quantity > 0 AND sales > 0 AND unit_price > 0 THEN 'Case 27: q>0, s>0, p>0'
#   END AS case_label
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step3_sales`
# WHERE sales <= 0 OR quantity <= 0 OR unit_price <= 0;
# 
# SELECT * FROM `ecommerce-petshop-costopt.ecommerce_petshop.step6_rangechecks`;
#

"""### ðŸ”¹ **Count of Cases**"""

# Commented out IPython magic to ensure Python compatibility.
# # STEP_4 - sales table - checking for metric ranges - count cases
# 
# %%bigquery
# WITH
# case_1 AS (
#   SELECT COUNT(*) AS count_case_1
#   FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_rangechek`
#   WHERE case_label = 'Case 1: q<0, s<0, p<0'
# ),
# case_2 AS (
#   SELECT COUNT(*) AS count_case_2
#   FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_rangechek`
#   WHERE case_label = 'Case 2: q<0, s<0, p=0'
# ),
# case_3 AS (
#   SELECT COUNT(*) AS count_case_3
#   FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_rangechek`
#   WHERE case_label = 'Case 3: q<0, s<0, p>0'
# ),
# case_4 AS (
#   SELECT COUNT(*) AS count_case_4
#   FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_rangechek`
#   WHERE case_label = 'Case 4: q<0, s=0, p<0'
# ),
# case_5 AS (
#   SELECT COUNT(*) AS count_case_5
#   FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_rangechek`
#   WHERE case_label = 'Case 5: q<0, s=0, p=0'
# ),
# case_6 AS (
#   SELECT COUNT(*) AS count_case_6
#   FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_rangechek`
#   WHERE case_label = 'Case 6: q<0, s=0, p>0'
# ),
# case_7 AS (
#   SELECT COUNT(*) AS count_case_7
#   FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_rangechek`
#   WHERE case_label = 'Case 7: q<0, s>0, p<0'
# ),
# case_8 AS (
#   SELECT COUNT(*) AS count_case_8
#   FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_rangechek`
#   WHERE case_label = 'Case 8: q<0, s>0, p=0'
# ),
# case_9 AS (
#   SELECT COUNT(*) AS count_case_9
#   FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_rangechek`
#   WHERE case_label = 'Case 9: q<0, s>0, p>0'
# ),
# case_10 AS (
#   SELECT COUNT(*) AS count_case_10
#   FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_rangechek`
#   WHERE case_label = 'Case 10: q=0, s<0, p<0'
# ),
# case_11 AS (
#   SELECT COUNT(*) AS count_case_11
#   FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_rangechek`
#   WHERE case_label = 'Case 11: q=0, s<0, p=0'
# ),
# case_12 AS (
#   SELECT COUNT(*) AS count_case_12
#   FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_rangechek`
#   WHERE case_label = 'Case 12: q=0, s<0, p>0'
# ),
# case_13 AS (
#   SELECT COUNT(*) AS count_case_13
#   FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_rangechek`
#   WHERE case_label = 'Case 13: q=0, s=0, p<0'
# ),
# case_14 AS (
#   SELECT COUNT(*) AS count_case_14
#   FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_rangechek`
#   WHERE case_label = 'Case 14: q=0, s=0, p=0'
# ),
# case_15 AS (
#   SELECT COUNT(*) AS count_case_15
#   FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_rangechek`
#   WHERE case_label = 'Case 15: q=0, s=0, p>0'
# ),
# case_16 AS (
#   SELECT COUNT(*) AS count_case_16
#   FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_rangechek`
#   WHERE case_label = 'Case 16: q=0, s>0, p<0'
# ),
# case_17 AS (
#   SELECT COUNT(*) AS count_case_17
#   FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_rangechek`
#   WHERE case_label = 'Case 17: q=0, s>0, p=0'
# ),
# case_18 AS (
#   SELECT COUNT(*) AS count_case_18
#   FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_rangechek`
#   WHERE case_label = 'Case 18: q=0, s>0, p>0'
# ),
# case_19 AS (
#   SELECT COUNT(*) AS count_case_19
#   FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_rangechek`
#   WHERE case_label = 'Case 19: q>0, s<0, p<0'
# ),
# case_20 AS (
#   SELECT COUNT(*) AS count_case_20
#   FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_rangechek`
#   WHERE case_label = 'Case 20: q>0, s<0, p=0'
# ),
# case_21 AS (
#   SELECT COUNT(*) AS count_case_21
#   FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_rangechek`
#   WHERE case_label = 'Case 21: q>0, s<0, p>0'
# ),
# case_22 AS (
#   SELECT COUNT(*) AS count_case_22
#   FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_rangechek`
#   WHERE case_label = 'Case 22: q>0, s=0, p<0'
# ),
# case_23 AS (
#   SELECT COUNT(*) AS count_case_23
#   FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_rangechek`
#   WHERE case_label = 'Case 23: q>0, s=0, p=0'
# ),
# case_24 AS (
#   SELECT COUNT(*) AS count_case_24
#   FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_rangechek`
#   WHERE case_label = 'Case 24: q>0, s=0, p>0'
# ),
# case_25 AS (
#   SELECT COUNT(*) AS count_case_25
#   FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_rangechek`
#   WHERE case_label = 'Case 25: q>0, s>0, p<0'
# ),
# case_26 AS (
#   SELECT COUNT(*) AS count_case_26
#   FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_rangechek`
#   WHERE case_label = 'Case 26: q>0, s>0, p=0'
# ),
# case_27 AS (
#   SELECT COUNT(*) AS count_case_27
#   FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_rangechek`
#   WHERE case_label = 'Case 27: q>0, s>0, p>0'
# )
# 
# SELECT *
# FROM case_1, case_2, case_3, case_4, case_5, case_6, case_7, case_8, case_9,
#      case_10, case_11, case_12, case_13, case_14, case_15, case_16, case_17, case_18,
#      case_19, case_20, case_21, case_22, case_23, case_24, case_25, case_26, case_27;
#

"""**Interpretation of Cases**

**Case 3 (160 rows) â†’ `quantity < 0, sales < 0, unit_price > 0`**  
**Possible Meaning:** Could be returns, if a matching positive sales line exists.  
**Action:**  
- Do a self-join on `customer_id`, `invoice_id`, `quantity`, `sales`, and `unit_price`  
  to see if there is an identical sales record.  
- Internal check (discuss with business team).  

---

**Case 5 (16 rows) â†’ `quantity < 0, sales = 0, unit_price = 0`**  
**Possible Meaning:** No clear explanation.  
**Action:**  
- Internal check (discuss with business team).  

---

**Case 15 (475 rows) â†’ `quantity = 0, sales = 0, unit_price > 0`**  
**Possible Meaning:** Wrong booking â€“ quantity was left at 0, which leads automatically to sales = 0.  
**Action:**  
- Internal check (discuss with business team).  

---

**Case 23 (44 rows) â†’ `quantity > 0, sales = 0, unit_price = 0`**  
**Possible Meaning:** Could be a free service given or a free item.  
**Action:**  
- Internal check (discuss with business team).  

---

> All other cases (1â€“2, 4, 6â€“14, 16â€“22, 24â€“27) do **not appear in the dataset**, so they can be excluded.

---

**Note:** Please note that this analysis is based on **fictitious data** only.

### ðŸ”¹ **Cheking for Case 3 (`quantity < 0, sales < 0, unit_price > 0`)**
"""

# Commented out IPython magic to ensure Python compatibility.
# # STEP_4 - sales table - checking for metric ranges - cheking for case 3
# 
# %%bigquery
# SELECT invoice_no, customer_id, case_label
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_rangechek`
# WHERE case_label = 'Case 3: q<0, s<0, p>0'

# Commented out IPython magic to ensure Python compatibility.
# # STEP_ - sales table - checking for case 3 (`quantity < 0, sales < 0, unit_price > 0`)
# 
# %%bigquery
# WITH negative AS (
# SELECT *
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step3_sales`
# WHERE sales < 0
# ),
# 
# positive AS (
# SELECT *
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step3_sales`
# WHERE sales >0
# )
# 
# SELECT n.sales AS sales_neg, n.unit_price AS price_neg, n.quantity AS quantity_neg, p.sales AS sales_pos, p.unit_price AS price_pos, p.quantity AS quantity_pos
# FROM negative n
# JOIN positive p
#   ON n.customer_id = p.customer_id
#   AND n.quantity     = p.quantity
#   AND n.sales        = p.sales
#   AND n.unit_price   = p.unit_price
# 
# 
# 
#

"""**Result of Case 3 Check**

**Case 3 â†’ `quantity < 0, sales < 0, unit_price > 0`**

- **Result:** No matching positive sales lines were found.  
  â†’ This case **cannot be explained by returns**.  
  â†’ The only possible action would be to **discuss with the business team**.  

---

**Action for further analysis:**  
Since we are working with **fictitious data** and internal checks are not possible,  
we will filter the dataset to keep only:  

- `quantity > 0`  
- `sales > 0`  
- `unit_price > 0`  

This ensures that only valid transactions remain for analysis.

### ðŸ”¹ **Filtering sales table for `quantity > 0, sales > 0, unit_price > 0`**
"""

# Commented out IPython magic to ensure Python compatibility.
# # Step 4 â€” Filtering sales table for (quantity > 0, sales > 0, unit_price > 0)
# 
# %%bigquery
# CREATE OR REPLACE VIEW `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_sales` AS
# SELECT *
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step3_sales`
# WHERE quantity > 0 AND sales > 0 AND unit_price > 0;

"""## ðŸ”µ **Step 5 â€” Joining all tables**  

In this step, we combine the **'inter_step4_sales)'** with the additional reference tables.  

- **Customer table (`inter_step1_cust`)** â†’ enriches order line items with customer information.  
- **State table (`inter_step1_state`)** â†’ adds geographic details linked via `state_initials`.  
- **Product table (`inter_step1_prod`)** â†’ provides complete product descriptions and metadata.  
- **Final unified view (`inter_step5_join`)** â†’ clean, unified dataset that contains `NULL` values for categorical columns.  
- **Final unified view (`inter_step5_join_unknown`)** â†’ same as `inter_step5_join`, but:  
  - categorical columns with `NULL` values are replaced by `'Unknown'`  




**Important Issues**  
- Ensures that missing **descriptions** in the sales table are filled from the product table.  
- Uses a **COALESCE join** on `stock_code` and `description` so that even if the `stock_code` is missing, the product description can still be matched.  
- Avoids duplicate key columns (e.g., `customer_id`, `state_initials`, `stock_code`) by using `EXCEPT`.  
- Creates a **clean fallback version** (`inter_step5_join_unknown`), where all categorical nulls are standardized as `'Unknown'`, while numeric and date fields remain as `NULL` to keep averages correct.  
- Additionally, we explicitly filter out rows where **`stock_code IS NULL`** or **`transaction_date IS NULL`** because:  
  1. **Unknown product pairs** do not provide value for cross-selling analysis.  
  2. Rows with missing `stock_code` or `transaction_date` would otherwise lead to **different data foundations** in aggregations and dashboard visualizations, creating inconsistent KPI baselines.  
  
  - `stock_code` must always be present (no nulls kept)  
  - `transaction_date` must always be present (no nulls kept)

>The matching logic was finalised at the intermediate stage, and the dataset is now prepared for the Datamart layer.


"""

# Commented out IPython magic to ensure Python compatibility.
# # Step 5 â€” Joining all tables
# 
# %%bigquery
# CREATE OR REPLACE VIEW `ecommerce-petshop-costopt.ecommerce_petshop.inter_step5_join` AS
# SELECT
#     sales.* EXCEPT(description, stock_code, customer_id),
#     cust.* EXCEPT(state_initials),
#     state.*,
#     prod.*
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step4_sales` AS sales
# LEFT JOIN `ecommerce-petshop-costopt.ecommerce_petshop.inter_step1_cust` AS cust
#   ON sales.customer_id = cust.customer_id
# LEFT JOIN `ecommerce-petshop-costopt.ecommerce_petshop.inter_step1_state` AS state
#   ON cust.state_initials = state.state_initials
# LEFT JOIN `ecommerce-petshop-costopt.ecommerce_petshop.inter_step1_prod` AS prod
#   ON COALESCE(sales.stock_code, sales.description) = COALESCE(prod.stock_code, prod.description)

# Commented out IPython magic to ensure Python compatibility.
# # Step 7 â€” View inter_step5_join
# 
# %%bigquery
# SELECT *
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step5_join`
# LIMIT 1000;

# Commented out IPython magic to ensure Python compatibility.
# # Step 7 â€” Joining all tables - Nulls to Unknown
# 
# %%bigquery
# CREATE OR REPLACE VIEW `ecommerce-petshop-costopt.ecommerce_petshop.inter_step5_join_unknown` AS
# SELECT
#   order_line_item,
#   transaction_date,
#   --CASE WHEN transaction_date IS NULL THEN 'Unknown' ELSE transaction_date END AS transaction_date,
#   CASE WHEN invoice_no IS NULL THEN 'Unknown' ELSE invoice_no END AS invoice_no,
#   quantity,
#   sales,
#   unit_price,
#   CASE WHEN customer_id IS NULL THEN 'Unknown' ELSE customer_id END AS customer_id,
#   CASE WHEN order_city IS NULL THEN 'Unknown' ELSE order_city END AS order_city,
#   CASE WHEN order_postal IS NULL THEN 'Unknown' ELSE order_postal END AS order_postal,
#   latitude,
#   longitude,
#   CASE WHEN state_initials IS NULL THEN 'Unknown' ELSE state_initials END AS state_initials,
#   CASE WHEN state_name IS NULL THEN 'Unknown' ELSE state_name END AS state_name,
#   CASE WHEN region IS NULL THEN 'Unknown' ELSE region END AS region,
#   stock_code,
#   weight,
#   landed_cost,
#   shipping_cost_1000_mile,
#   CASE WHEN description IS NULL THEN 'Unknown' ELSE description END AS description,
#   CASE WHEN category IS NULL THEN 'Unknown' ELSE category END AS category
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step5_join`
# WHERE stock_code IS NOT NULL AND transaction_date IS NOT NULL;
#

# Commented out IPython magic to ensure Python compatibility.
# # Step 7 â€” View inter_step5_join_unknown
# 
# %%bigquery
# SELECT *
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step5_join_unknown`
# LIMIT 1000;

"""# ðŸŸ¦ **3. Datamart Layer**

## ðŸ”µ **Step 1 - Pair Building Logic**
"""

# Commented out IPython magic to ensure Python compatibility.
# %%bigquery
# CREATE OR REPLACE VIEW `ecommerce-petshop-costopt.ecommerce_petshop.pair_building` AS
# 
# --------------------------------------------------------------------------------------------------------------------------
# # 1. Single Metrics - Level: transaction_quarter, stock_code, invoice_no
# --------------------------------------------------------------------------------------------------------------------------
# 
# WITH single_metrics_1 AS (
#  SELECT
#     DATE_TRUNC(transaction_date, QUARTER) AS transaction_quarter,
#     invoice_no,
#     stock_code,
#     AVG(unit_price) AS avg_unit_price,
#     SUM(sales) AS sum_sales,
#     SUM(sales-(landed_cost*quantity)) AS sum_profit,
#     SAFE_DIVIDE(SUM(sales-(landed_cost*quantity)), SUM(sales)) AS margin
#   FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step5_join_unknown`
#   GROUP BY transaction_quarter, stock_code, invoice_no
# )
# 
# --------------------------------------------------------------------------------------------------------------------------
# # 2. Pair Building - Level: transaction_quarter, stock_code_a, stock_code_b, invoice_no
# --------------------------------------------------------------------------------------------------------------------------
# 
# 
# SELECT
#     a.invoice_no,
#     a.transaction_quarter,
#     a.stock_code AS product_a,
#     b.stock_code AS product_b,
#     a.avg_unit_price AS avg_unit_price_a,
#     b.avg_unit_price AS avg_unit_price_b,
#     a.sum_sales AS sum_sales_a,
#     b.sum_sales AS sum_sales_b,
#     a.sum_profit AS sum_profit_a,
#     b.sum_profit AS sum_profit_b,
#     a.margin AS margin_a,
#     b.margin AS margin_b
# FROM single_metrics_1 a
# JOIN single_metrics_1 b
#   ON a.invoice_no = b.invoice_no
#   AND a.transaction_quarter = b.transaction_quarter
#   AND a.stock_code < b.stock_code
#  WHERE a.transaction_quarter IS NOT NULL
#

# Commented out IPython magic to ensure Python compatibility.
# %%bigquery
# SELECT
#   *
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.pair_building`;

"""### ðŸ”¹ **Documentation for View:** `ecommerce_petshop.pair_building`

This view is responsible for identifying which products were bought together in the same specific transaction (Invoice). It creates the "basket" pairs.

---

**Data Basis & Aggregation Level**

**Input Table:** `inter_step5_join_unknown`
**Output Level:** Transaction Quarter, Invoice Number, Product A, Product B.

**What happens here?**
We do not aggregate by quarter yet. We look at every single invoice individually to see which items appear together.

---

**1. Step-by-Step Calculation (Walkthrough)**

We use an example of one invoice (**Invoice #1001**) containing 3 products: **Dog Food (A)**, **Cat Food (B)**, and **Bird Cage (C)**.

**Step A: Calculate Single Metrics (CTE `single_metrics_1`)**

First, we calculate the sales and profit for every line item in the invoice.
*Level: Quarter, Invoice, Stock Code*

| transaction_quarter | invoice_no | stock_code | avg_unit_price | sum_sales | sum_profit |
|---------------------|------------|------------|----------------|-----------|------------|
| 2025-07-01 (Q3)     | 1001       | **A** | 10.00          | 20.00     | 5.00       |
| 2025-07-01 (Q3)     | 1001       | **B** | 5.00           | 5.00      | 2.00       |
| 2025-07-01 (Q3)     | 1001       | **C** | 50.00          | 50.00     | 10.00      |

**Formulas:**
* `sum_profit` = Sales - (Landed Cost * Quantity)
* `margin` = Profit / Sales

---

**2. Pair Creation (Self-Join)**

We join the table with itself to find combinations.
*Condition:* `a.invoice_no = b.invoice_no` AND `a.stock_code < b.stock_code`

**Why `stock_code < stock_code`?**
This prevents duplicates and self-pairs.
* It prevents **A-A** (pairing a product with itself).
* It prevents **B-A** (if we already have **A-B**, we do not need B-A).

**Resulting Pairs for Invoice #1001:**

| invoice_no | product_a | product_b | sum_sales_a | sum_sales_b | sum_profit_a | sum_profit_b |
|------------|-----------|-----------|-------------|-------------|--------------|--------------|
| 1001       | **A** | **B** | 20.00       | 5.00        | 5.00         | 2.00         |
| 1001       | **A** | **C** | 20.00       | 50.00       | 5.00         | 10.00        |
| 1001       | **B** | **C** | 5.00        | 50.00       | 2.00         | 10.00        |

---

**Summary of the Final View**

The view `pair_building` contains the following columns:

**1. Identifiers**
* `invoice_no`: The unique ID of the shopping basket.
* `transaction_quarter`: The quarter in which the purchase happened.
* `product_a`: The stock code of the first product.
* `product_b`: The stock code of the second product.

**2. Metrics for Product A (in this specific invoice)**
* `avg_unit_price_a`
* `sum_sales_a`
* `sum_profit_a`
* `margin_a`

**3. Metrics for Product B (in this specific invoice)**
* `avg_unit_price_b`
* `sum_sales_b`
* `sum_profit_b`
* `margin_b`

## ðŸ”µ**Step 2 - Final Main Table - Market Basket Analysis & KPI Logic**
"""

# Commented out IPython magic to ensure Python compatibility.
# %%bigquery
# CREATE OR REPLACE VIEW `ecommerce-petshop-costopt.ecommerce_petshop.final_table` AS
# 
# --------------------------------------------------------------------------------------------------------------------------
# # Step A: Input Metrics (CTEs 1-4)
# --------------------------------------------------------------------------------------------------------------------------
# ## 1. Single Metrics & Pair Count -  Level: transaction_quarter, stock_code_a, stock_code_b
# --------------------------------------------------------------------------------------------------------------------------
# 
# WITH single_metrics_2 AS (
# 
# SELECT
#     transaction_quarter,
#     product_a,
#     product_b,
#     AVG(avg_unit_price_a) AS avg_unit_price_a,
#     AVG(avg_unit_price_b) AS avg_unit_price_b,
#     SUM(sum_sales_a) AS sum_sales_a,
#     SUM(sum_sales_b) AS sum_sales_b,
#     SUM(sum_profit_a) AS sum_profit_a,
#     SUM(sum_profit_b) AS sum_profit_b,
#     SAFE_DIVIDE(SUM(sum_profit_a), SUM(sum_sales_a)) AS margin_a,
#     SAFE_DIVIDE(SUM(sum_profit_b), SUM(sum_sales_b)) AS margin_b,
#     COUNT(DISTINCT invoice_no) AS count_trans_pair
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.pair_building`
# GROUP BY transaction_quarter, product_a, product_b
# ),
# 
# 
# --------------------------------------------------------------------------------------------------------------------------
# # 2. Single Count - Level: transaction_quarter, stock_code, invoice_no
# --------------------------------------------------------------------------------------------------------------------------
# single_count AS (
# 
#  SELECT
#     DATE_TRUNC(transaction_date, QUARTER) AS transaction_quarter,
#     stock_code,
#     COUNT(DISTINCT invoice_no) AS single_count
#   FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step5_join_unknown`
#   GROUP BY transaction_quarter, stock_code
# ),
# 
# --------------------------------------------------------------------------------------------------------------------------
# # 3. Total Count - Level: transaction_quarter
# --------------------------------------------------------------------------------------------------------------------------
# 
# count_all_transactions AS (
# SELECT
#     DATE_TRUNC(transaction_date, QUARTER) AS transaction_quarter,
#     COUNT(DISTINCT invoice_no) AS count_trans_tot
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step5_join_unknown`
# GROUP BY transaction_quarter
# ),
# 
# --------------------------------------------------------------------------------------------------------------------------
# # 4. Product Descriptions - Level: stock_code
# --------------------------------------------------------------------------------------------------------------------------
# 
# product_descriptions AS (
#   SELECT
#     stock_code,
#     MAX(description) AS description
#   FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step5_join_unknown`
#   GROUP BY stock_code
# ),
# 
# --------------------------------------------------------------------------------------------------------------------------
# # Step B: KPI Calculation (MBA)
# --------------------------------------------------------------------------------------------------------------------------
# ## 5. Bring all together (global metrics only) -  Level: transaction_quarter, stock_code_a, stock_code_b
# --------------------------------------------------------------------------------------------------------------------------
# 
# all_together AS (
# SELECT
# 
#   sm2.*,
#   sc_a.single_count AS count_trans_a,
#   sc_b.single_count AS count_trans_b,
#   cat.count_trans_tot,
#   pd_a.description AS description_a,
#   pd_b.description AS description_b
# 
# FROM single_metrics_2 sm2
# JOIN single_count sc_a
#   ON sm2.transaction_quarter = sc_a.transaction_quarter
#   AND sm2.product_a = sc_a.stock_code
# JOIN single_count sc_b
#   ON sm2.transaction_quarter = sc_b.transaction_quarter
#   AND sm2.product_b = sc_b.stock_code
# JOIN count_all_transactions cat
#   ON sm2.transaction_quarter = cat.transaction_quarter
# JOIN product_descriptions pd_a
#   ON sm2.product_a = pd_a.stock_code
# JOIN product_descriptions pd_b
#   ON sm2.product_b = pd_b.stock_code
# ),
# 
# 
# --------------------------------------------------------------------------------------------------------------------------
# # 6. KPIS Step 1 - Level: transaction_quarter, stock_code_a, stock_code_b
# --------------------------------------------------------------------------------------------------------------------------
# 
# kpi_step1 AS(
# SELECT
#     * EXCEPT(avg_unit_price_a, sum_sales_a, sum_profit_a, margin_a,
#              avg_unit_price_b, sum_sales_b, sum_profit_b, margin_b),
#     SAFE_DIVIDE((avg_unit_price_a + avg_unit_price_b), 2) AS avg_price_pair,
#     (sum_sales_a + sum_sales_b) AS total_sales_pair,
#     SAFE_DIVIDE((sum_profit_a + sum_profit_b), (sum_sales_a + sum_sales_b)) AS avg_margin_pair,
#     (sum_profit_a + sum_profit_b) AS total_profit_pair,
#     SAFE_DIVIDE(count_trans_a, count_trans_tot) AS support_product_a,
#     SAFE_DIVIDE(count_trans_b, count_trans_tot) AS support_product_b,
#     SAFE_DIVIDE(count_trans_pair, count_trans_tot) AS support_pair,
# 
# FROM all_together
# ),
# 
# --------------------------------------------------------------------------------------------------------------------------
# # Step C: Fixed Metrics & Benchmarks
# --------------------------------------------------------------------------------------------------------------------------
# # 7. KPIS Step 2 - Level: transaction_quarter, stock_code_a, stock_code_b
# --------------------------------------------------------------------------------------------------------------------------
# 
# kpi_step2 AS(
# SELECT
#     kpi_1.*,
#     SAFE_DIVIDE(kpi_1.support_pair,kpi_1.support_product_a) AS confidence,
#     SAFE_DIVIDE(kpi_1.support_pair,(kpi_1.support_product_a*kpi_1.support_product_b)) AS lift
# FROM kpi_step1 AS kpi_1
# ),
# 
# --------------------------------------------------------------------------------------------------------------------------
# # 8. Fixed Metrics vor KPI Charts-final - Level: transaction_quarter, stock_code_a, stock_code_b
# --------------------------------------------------------------------------------------------------------------------------
# 
# fixed_metrics_kpi AS(
# SELECT
#     kpi_2.*,
#     AVG(kpi_2.total_sales_pair) OVER() AS fixed_avg_total_sales_pair,
#     AVG(kpi_2.total_profit_pair) OVER() AS fixed_avg_total_profit_pair,
#     AVG(kpi_2.avg_price_pair) OVER() AS fixed_avg_price_pair,
#     AVG(kpi_2.avg_margin_pair) OVER() AS fixed_avg_margin_pair,
#     AVG(kpi_2.support_pair) OVER() AS fixed_avg_support_pair,
#     AVG(kpi_2.confidence) OVER() AS fixed_avg_confidence,
#     AVG(kpi_2.lift) OVER() AS fixed_avg_lift
# FROM kpi_step2 kpi_2
# ),
# 
# --------------------------------------------------------------------------------------------------------------------------
# #### Step D: Time Windows (Time Buckets)
# --------------------------------------------------------------------------------------------------------------------------
# # 9. last Quarterdate - Level: (global Scalar)
# --------------------------------------------------------------------------------------------------------------------------
# 
# max_querterdate AS (
#   SELECT DATE(MAX(transaction_quarter)) AS max_date
#   FROM kpi_step2
# )
# 
# --------------------------------------------------------------------------------------------------------------------------
# # 10. Time Windows (3M / 6M / 9M / 12M) - Level: transaction_quarter, stock_code_a, stock_code_b
# --------------------------------------------------------------------------------------------------------------------------
# 
# SELECT
# 
#   fmk.*,
# 
#   -- Boolean-Flags (Time Buckets)
#   CASE
#     WHEN DATE_DIFF(m.max_date, DATE(fmk.transaction_quarter), MONTH) <= 3
#     THEN TRUE
#     ELSE FALSE
#   END AS is_3m,
# 
#   CASE
#     WHEN DATE_DIFF(m.max_date, DATE(fmk.transaction_quarter), MONTH) <= 6
#     THEN TRUE
#     ELSE FALSE
#   END AS is_6m,
# 
#   CASE
#     WHEN DATE_DIFF(m.max_date, DATE(fmk.transaction_quarter), MONTH) <= 9
#     THEN TRUE
#     ELSE FALSE
#   END AS is_9m,
# 
#   CASE WHEN DATE_DIFF(m.max_date, DATE(fmk.transaction_quarter), MONTH) <= 12
#     THEN TRUE
#     ELSE FALSE
#   END AS is_12m,
# 
# FROM fixed_metrics_kpi fmk
# CROSS JOIN max_querterdate m;

# Commented out IPython magic to ensure Python compatibility.
# %%bigquery
# SELECT *
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.final_table`;

"""### ðŸ”¹ **Documentation for View:** `ecommerce_petshop.final_table`

This process groups transaction data by **Transaction Quarter, Product A, and Product B**. It calculates association rules (Confidence, Lift) for each specific pair over time and adds time filters for reporting.

---

**1. Data Basis & Aggregation Level**

The analysis does not look at single days. It aggregates data at the following level:
* **Transaction Quarter**
* **Stock Code A** (First Product)
* **Stock Code B** (Second Product)

**Tables used:**
1.  **`pair_building`**: Contains combined financial data (sales, profit) for specific product pairs.
2.  **`inter_step5_join_unknown`**: Cleaned data (from inetrmediate stage) for single product counts and total transaction counts.

---

**2. Step-by-Step Calculation (Walkthrough)**

We simulate the calculation with an example of **2 Quarters** for the pair **Product A + Product B**.

**Step A: Input Metrics (CTEs 1-4)**

**1. (`single_metrics_2`)**
This data comes from the pair table.
*Level: Quarter, Product A, Product B*

| transaction_quarter | product_a | product_b | sum_sales_a | sum_sales_b | count_trans_pair |
|---------------------|-----------|-----------|-------------|-------------|------------------|
| 2025-07-01 (Q3)     | A         | B         | 100         | 50          | **10** |
| 2025-10-01 (Q4)     | A         | B         | 120         | 60          | **5** |

**2. (`single_count`)**
How often was Product A (or B) bought in total during that quarter?
*Level: Quarter, Stock Code*

| transaction_quarter | stock_code | single_count |
|---------------------|------------|--------------|
| 2025-07-01 (Q3)     | A          | 20           |
| 2025-07-01 (Q3)     | B          | 15           |
| 2025-10-01 (Q4)     | A          | 10           |

**3. Total Transactions (`count_all_transactions`)**
The total number of invoices (baskets) in the quarter.
*Level: Quarter*

| transaction_quarter | count_trans_tot |
|---------------------|-----------------|
| 2025-07-01 (Q3)     | **100** |
| 2025-10-01 (Q4)     | **50** |

**4. Product Descriptions (`product_descriptions`)**
We need the text names of the products to make the report readable.
*Level: Stock Code*

| stock_code | description |
|------------|-------------|
| A          | Dog Food    |
| B          | Cat Food    |
---

**Step B: KPI Calculation (MBA)**

Here we calculate **Support**, **Confidence**, and **Lift** for the pair A+B in each quarter.

**Formulas:**

1.  **Support (Pair):** The percentage of transactions that contain both products.
    *Formula: count_trans_pair / count_trans_tot*

2.  **Confidence:** How likely is it to buy B if you buy A?
    *Formula: Support(Pair) / Support(A)*

3.  **Lift:** How much more often do A and B appear together than by random chance?
    *Formula: Confidence / Support(B)*

**Results Table (`kpi_step1` & `kpi_step2` combined):**

| transaction_quarter | product_a | product_b | support_product_a | support_product_b | support_pair | confidence | lift |
|---------------------|-----------|-----------|-------------------|-------------------|--------------|------------|------|
| 2025-07-01 (Q3)     | A         | B         | 0.20              | 0.15              | 0.10         | **0.50** | **3.33** |
| 2025-10-01 (Q4)     | A         | B         | 0.20              | 0.16              | 0.10         | **0.50** | **3.12** |

**Example Calculation (for Q3):**

* **Support A:** 20 / 100 = 0.20
* **Support B:** 15 / 100 = 0.15
* **Support Pair:** 10 / 100 = **0.10**
* **Confidence:** 0.10 / 0.20 = **0.50** (50% of people who bought A also bought B)
* **Lift:** 0.10 / (0.20 * 0.15) = **3.33** (Strong positive connection)
---

**Step C: Fixed Metrics & Benchmarks**

To allow comparisons in a dashboard, the code calculates the average over **all time** for the specific pair (using window functions).

| Quarter | Pair | Lift | Fixed_Avg_Lift (Benchmark) |
|---------|------|------|----------------------------|
| Q3      | A-B  | 3.33 | 3.22                       |
| Q4      | A-B  | 3.12 | 3.22                       |

---

**Step D: Time Windows (Time Buckets)**

The code finds the **latest date** in the data (`max_querterdate`) and creates "True/False" flags for each row.

*Assumed Max Date: 2025-10-01 (Q4)*

| transaction_quarter | Diff (Months) | is_3m | is_6m | is_12m |
|---------------------|---------------|-------|-------|--------|
| **2025-10-01 (Q4)** | 0             | TRUE  | TRUE  | TRUE   |
| **2025-07-01 (Q3)** | 3             | TRUE  | TRUE  | TRUE   |
| **2025-04-01 (Q2)** | 6             | FALSE | TRUE  | TRUE   |
| **2024-10-01** | 12            | FALSE | FALSE | TRUE   |

**Logic:**
* `is_3m`: TRUE if the quarter is within the last 3 months.
* This allows dashboard filters like "Show performance of the last 6 months".

---

**Summary of the Final Table**

The final view (`final_table`) contains the following columns:

**1. Identification & Descriptions**
* `transaction_quarter`: The timeframe of the analysis.
* `product_a`: Stock code of the first product.
* `product_b`: Stock code of the second product.
* `description_a`: Name of the first product.
* `description_b`: Name of the second product.

**2. Transaction Counts**
* `count_trans_pair`: How often A and B were bought together.
* `count_trans_a`: How often A was bought in total.
* `count_trans_b`: How often B was bought in total.
* `count_trans_tot`: Total number of transactions in the quarter.

**3. Pair Financials**
* `avg_price_pair`: Average combined unit price of A and B.
* `total_sales_pair`: Total revenue generated by this pair.
* `avg_margin_pair`: Average profit margin of this pair.
* `total_profit_pair`: Total profit generated by this pair.

**4. Market Basket Analysis (MBA) Metrics**
* `support_product_a`: Popularity of Product A.
* `support_product_b`: Popularity of Product B.
* `support_pair`: Frequency of the pair appearing together.
* `confidence`: Probability of buying B when buying A.
* `lift`: Strength of the relationship ( > 1 means positive correlation).

**5. Fixed Benchmarks (Global Averages)**
* `fixed_avg_total_sales_pair`: Global average sales per pair.
* `fixed_avg_total_profit_pair`: Global average profit per pair.
* `fixed_avg_price_pair`: Global average price per pair.
* `fixed_avg_margin_pair`: Global average margin per pair.
* `fixed_avg_support_pair`: Global average support.
* `fixed_avg_confidence`: Global average confidence.
* `fixed_avg_lift`: Global average lift.

**6. Time Filters (Boolean Flags)**
* `is_3m` / `is_6m` / `is_9m` / `is_12m`: True/False flags to filter for the last 3, 6, 9, or 12 months.

## ðŸ”µ **Step 3 - Cross-Sell Rate (CSR) Logic**
"""

# Commented out IPython magic to ensure Python compatibility.
# %%bigquery
# CREATE OR REPLACE VIEW `ecommerce-petshop-costopt.ecommerce_petshop.csr` AS
# 
# --------------------------------------------------------------------------------------------------------------------------
# # 1. Qaurterly Pair Count - Level: transaction_quarter
# --------------------------------------------------------------------------------------------------------------------------
# 
# WITH q_pair_count AS (
# SELECT transaction_quarter,
#     COUNT(DISTINCT invoice_no) AS count_trans_pair_quarter
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.pair_building`
# GROUP BY transaction_quarter
# ),
# 
# --------------------------------------------------------------------------------------------------------------------------
# # 2. Total Count - Level: transaction_quarter
# --------------------------------------------------------------------------------------------------------------------------
# 
# count_all_transactions AS (
# SELECT
#     DATE_TRUNC(transaction_date, QUARTER) AS transaction_quarter,
#     COUNT(DISTINCT invoice_no) AS count_trans_tot
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.inter_step5_join_unknown`
# GROUP BY transaction_quarter
# )
# 
# --------------------------------------------------------------------------------------------------------------------------
# # 3. Cross-Sell Rate - Level: transaction_quarter
# --------------------------------------------------------------------------------------------------------------------------
# 
# SELECT
#     qpc.transaction_quarter,
#     SAFE_DIVIDE(qpc.count_trans_pair_quarter, cat.count_trans_tot) AS cross_sell_rate
# FROM q_pair_count qpc
# JOIN count_all_transactions cat
#   USING (transaction_quarter)

"""### ðŸ”¹ **Documentation for View:** `ecommerce_petshop.csr`

This view calculates the ratio of multi-item transactions to total transactions per quarter. It answers the question: "What percentage of our customers buy more than one product type?"

---

**Data Basis & Aggregation Level**

**Output Level:** Transaction Quarter

**Tables used:**
- **`pair_building`**: Contains only transactions that resulted in a pair (baskets with 2+ different items).
- **`inter_step5_join_unknown`**: Contains all transactions (single items and pairs).

---

We use an example of **Q3 2025**.

**1. Count Pair Transactions in Quarter (`q_pair_count`)**

We count how many unique invoices quaterly exist in the `pair_building` table. These are customers who bought at least 2 different items (Product A and Product B).

*Level: Transaction Quarter*

| transaction_quarter | count_trans_pair_quarter |
|---------------------|--------------------------|
| 2025-07-01 (Q3)     | **40** (Multi-item Baskets) |
| 2025-10-01 (Q4)     | **25** (Multi-item Baskets) |

**2. Count Total Transactions (`count_all_transactions`)**
We count the total number of unique invoices in the cleaned data(intermediate stage). This includes customers who bought single items AND customers who bought pairs.

*Level: Transaction Quarter*

| transaction_quarter | count_trans_tot |
|---------------------|-----------------|
| 2025-07-01 (Q3)     | **100** (Total Baskets) |
| 2025-10-01 (Q4)     | **50** (Total Baskets)  |

**3. Calculate Rate (Cross-Sell Rate)**
We join the tables and divide the Pair Count by the Total Count.

**Formula:**
* $CSR = \frac{\text{count\_trans\_pair\_quarter}}{\text{count\_trans\_tot}}$

**Calculation for Q3:**
* Pairs: 40
* Total: 100
* **CSR:** $40 / 100 = \mathbf{0.40}$

**Calculation for Q4:**
* Pairs: 25
* Total: 50
* **CSR:** $25 / 50 = \mathbf{0.50}$

---

**Summary of the Final View**

The final table `csr` looks like this:

| transaction_quarter | cross_sell_rate | Interpretation |
|---------------------|-----------------|----------------|
| 2025-07-01 (Q3)     | **0.40** | 40% of baskets contained multiple products. |
| 2025-10-01 (Q4)     | **0.50** | 50% of baskets contained multiple products. |

**Columns:**
1.  **`transaction_quarter`**: The timeframe of the analysis.
2.  **`cross_sell_rate`**: The efficiency metric.
    * **0.0:** No one buys pairs (single items only).
    * **1.0:** Everyone buys pairs (no single items).
"""

# Commented out IPython magic to ensure Python compatibility.
# %%bigquery
# SELECT
#   *
# FROM `ecommerce-petshop-costopt.ecommerce_petshop.csr`;

"""We have finished the full **data preparation process** and the dataset is now clean and ready.  

Next step:  
We can **load final table into Looker Studio** and start with the **Cross-Selling Analysis** and build our dashboard for insights.

# ðŸŸ¦ **4. EDA**

**Exploratory Data Analysis (EDA) â€“ Same Level as Dashboard**

In this step, we run an **Exploratory Data Analysis (EDA)** on the dataset `df_step9_final`.  
We use the **same level of aggregation** that will also be used later in the dashboard.  

This way, we make sure that all results, patterns, and metrics are already studied  
on the exact level where they will be shown and explained in the dashboard.  

By doing this, we better **understand the structure of the data** and keep everything  
consistent between the **analysis** and the **final dashboard**.
"""

# 4. EDA - Load Libraries

import pandas as pd
import matplotlib.pyplot as plt

# 4. EDA - Load dataset to pandas


## final main table
query = """
SELECT *
FROM `ecommerce-petshop-costopt.ecommerce_petshop.final_table`
"""

df_final_table = df = pd.read_gbq(query, project_id='ecommerce-petshop-costopt'
, dialect='standard')

## csr table
query = """
SELECT *
FROM `ecommerce-petshop-costopt.ecommerce_petshop.csr`
"""

df_csr = df = pd.read_gbq(query, project_id='ecommerce-petshop-costopt'
, dialect='standard')

display(df_final_table.columns)

# 1. Check date range of transaction_date

date_min = df_final_table["transaction_quarter"].min()
date_max = df_final_table["transaction_quarter"].max()

display("Date Range of User-Level Data:")
display(f"From: {date_min}")
display(f"To:   {date_max}")

# ------------------------------------------------------------------------------

# 2.0 Countplot for count_trans_pair by product_a + product_b

# Create the pair name first
df_final_table["pair"] = df_final_table["product_a"] + " & " + df_final_table["product_b"]

# IMPORTANT: Aggregate (Group and Sum)

df_grouped = df_final_table.groupby("pair")["count_trans_pair"].sum().reset_index()

# Sort by count and take the Top 50
top_pairs = df_grouped.sort_values("count_trans_pair", ascending=False).head(50)

# Plotting
plt.figure(figsize=(14, 8))

# Grid configuration (behind the bars)
plt.grid(axis='y', linestyle='--', alpha=0.7, zorder=0)

plt.bar(
    top_pairs["pair"],
    top_pairs["count_trans_pair"],
    color="skyblue",
    edgecolor="black",
    zorder=3 # Ensures bars are drawn on top of the grid
)

# Labels and Titles
plt.title("Top 50 Product Pairs by Transaction Volume")
plt.xlabel("Product Pair")
plt.ylabel("Total Transaction Count")
plt.xticks(rotation=90)

plt.tight_layout()
plt.show()

# ------------------------------------------------------------------------------

# 3.0 Boxplot, Histogramm, count_trans_pair

# Descriptive Statistics
display(f"Descriptive Statistics for Pair Transactions:")
display(df_final_table["count_trans_pair"].describe())

plt.figure(figsize=(12, 8))

# Boxplot
plt.subplot(1, 2, 1)
plt.boxplot(df_final_table["count_trans_pair"])
plt.title("Boxplot of Pair Transactions")
plt.ylabel("Count")

# Histogram
plt.subplot(1, 2, 2)
plt.hist(df_final_table["count_trans_pair"], bins=30, edgecolor="black")
plt.title("Histogram of Pair Transactions")
plt.xlabel("Count")
plt.ylabel("Frequency")

plt.show()

# ------------------------------------------------------------------------------

# 3.1 Boxplot, Histogramm, avg_price_pair

# Descriptive Statistics
display(f"Descriptive Statistics for Avg. Price of Pairs:")
display(df_final_table["avg_price_pair"].describe())

plt.figure(figsize=(12, 8))

# Boxplot
plt.subplot(1, 2, 1)
plt.boxplot(df_final_table["avg_price_pair"])
plt.title("Boxplot of Avg. Price of Pairs")
plt.ylabel("Avg. Price Pairs")

# Histogram
plt.subplot(1, 2, 2)
plt.hist(df_final_table["avg_price_pair"], bins=30, edgecolor="black")
plt.title("Histogram of Avg. Price of Pairs")
plt.xlabel("Avg. Price Pairs")
plt.ylabel("Frequency")

plt.show()

# ------------------------------------------------------------------------------

# 3.2 Boxplot, Histogramm, total_sales_pair

# Descriptive Statistics
display(f"Descriptive Statistics for Total Sales of Pairs:")
display(df_final_table["total_sales_pair"].describe())

plt.figure(figsize=(12, 8))

# Boxplot
plt.subplot(1, 2, 1)
plt.boxplot(df_final_table["total_sales_pair"])
plt.title("Boxplot of Total Sales of Pairs")
plt.ylabel("Total Sales")

# Histogram
plt.subplot(1, 2, 2)
plt.hist(df_final_table["total_sales_pair"], bins=30, edgecolor="black")
plt.title("Histogram of Total Sales of Pairs")
plt.xlabel("Total Sales")
plt.ylabel("Frequency")

plt.show()

# ------------------------------------------------------------------------------

# 3.3 Boxplot, Histogramm, avg_margin_pair

# Descriptive Statistics
display(f"Descriptive Statistics for Avg. Margin of Pairs:")
display(df_final_table["avg_margin_pair"].describe())

plt.figure(figsize=(12, 8))

# Boxplot
plt.subplot(1, 2, 1)
plt.boxplot(df_final_table["avg_margin_pair"])
plt.title("Boxplot of Avg. Margin of Pairs")
plt.ylabel("Avg. Margin")

# Histogram
plt.subplot(1, 2, 2)
plt.hist(df_final_table["avg_margin_pair"], bins=30, edgecolor="black")
plt.title("Histogram of Avg. Margin of Pairs")
plt.xlabel("Avg. Margin")
plt.ylabel("Frequency")

plt.show()

# ------------------------------------------------------------------------------

# 3.4 Boxplot, Histogramm, total_profit_pair

# Descriptive Statistics
display(f"Descriptive Statistics for Total Profit of Pairs:")
display(df_final_table["total_profit_pair"].describe())

plt.figure(figsize=(12, 8))

# Boxplot
plt.subplot(1, 2, 1)
plt.boxplot(df_final_table["total_profit_pair"])
plt.title("Boxplot of Total Profit of Pairs")
plt.ylabel("Total Profit")

# Histogram
plt.subplot(1, 2, 2)
plt.hist(df_final_table["total_profit_pair"], bins=30, edgecolor="black")
plt.title("Histogram of Total Profit of Pairs")
plt.xlabel("Total Profit")
plt.ylabel("Frequency")

plt.show()

# ------------------------------------------------------------------------------

# 3.5 Boxplot, Histogramm, support_product_a

# Descriptive Statistics
display(f"Descriptive Statistics for Support Product A:")
display(df_final_table["support_product_a"].describe())

plt.figure(figsize=(12, 8))

# Boxplot
plt.subplot(1, 2, 1)
plt.boxplot(df_final_table["support_product_a"])
plt.title("Boxplot of Support Product A")
plt.ylabel("Avg. Support Product A")

# Histogram
plt.subplot(1, 2, 2)
plt.hist(df_final_table["support_product_a"], bins=30, edgecolor="black")
plt.title("Histogram of Support Product A")
plt.xlabel("Avg. Support Product A")
plt.ylabel("Frequency")

plt.show()

# ------------------------------------------------------------------------------

# 3.6 Boxplot, Histogramm, support_product_b

# Descriptive Statistics
display(f"Descriptive Statistics for Support of Product B:")
display(df_final_table["support_product_b"].describe())

plt.figure(figsize=(12, 8))

# Boxplot
plt.subplot(1, 2, 1)
plt.boxplot(df_final_table["support_product_b"])
plt.title("Boxplot of Support of Product B")
plt.ylabel("Avg. Support of Product B")

# Histogram
plt.subplot(1, 2, 2)
plt.hist(df_final_table["support_product_b"], bins=30, edgecolor="black")
plt.title("Histogram of Support of Product B")
plt.xlabel("Avg. Support of Product B")
plt.ylabel("Frequency")

plt.show()

# ------------------------------------------------------------------------------

# 3.7 Boxplot, Histogramm, support_pair

# Descriptive Statistics
display(f"Descriptive Statistics for Support of Pairs:")
display(df_final_table["support_pair"].describe())

plt.figure(figsize=(12, 8))

# Boxplot
plt.subplot(1, 2, 1)
plt.boxplot(df_final_table["support_pair"])
plt.title("Boxplot of Support of Pairs")
plt.ylabel("Avg. Support Pairs")

# Histogram
plt.subplot(1, 2, 2)
plt.hist(df_final_table["support_pair"], bins=30, edgecolor="black")
plt.title("Histogram of Support of Pairs")
plt.xlabel("Avg. Support Pairs")
plt.ylabel("Frequency")

plt.show()

# ------------------------------------------------------------------------------

# 3.8 Boxplot, Histogramm, confidence

# Descriptive Statistics
display(f"Descriptive Statistics for Confidence of Pairs:")
display(df_final_table["confidence"].describe())

plt.figure(figsize=(12, 8))

# Boxplot
plt.subplot(1, 2, 1)
plt.boxplot(df_final_table["confidence"])
plt.title("Boxplot of Confidence of Pairs")
plt.ylabel("Avg. Confidence Pairs")

# Histogram
plt.subplot(1, 2, 2)
plt.hist(df_final_table["confidence"], bins=30, edgecolor="black")
plt.title("Histogram of Confidence of Pairs")
plt.xlabel("Avg. Confidence Pairs")
plt.ylabel("Frequency")

plt.show()

# ------------------------------------------------------------------------------

# 3.9 Boxplot, Histogramm, lift by

# Descriptive Statistics
display(f"Descriptive Statistics for Lift of Pairs:")
display(df_final_table["lift"].describe())

plt.figure(figsize=(12, 8))

# Boxplot
plt.subplot(1, 2, 1)
plt.boxplot(df_final_table["lift"])
plt.title("Boxplot of Lift of Pairs")
plt.ylabel("Avg. Lift Pairs")

# Histogram
plt.subplot(1, 2, 2)
plt.hist(df_final_table["lift"], bins=30, edgecolor="black")
plt.title("Histogram of Lift of Pairs")
plt.xlabel("Avg. Lift Pairs")
plt.ylabel("Frequency")

plt.show()

# ------------------------------------------------------------------------------


# 3.10 Barplot Cross_Sell Rate

# Descriptive Statistics
display(f"Descriptive Statistics for Cross_Sell Rate:")
display(df_csr["cross_sell_rate"].describe())

plt.figure(figsize=(10,5))
plt.bar(df_csr['transaction_quarter'].astype(str), df_csr['cross_sell_rate'])

plt.title("Cross-Sell Rate per Quarter")
plt.xlabel("Quarter")
plt.ylabel("Cross-Sell Rate")
plt.xticks(rotation=45)

plt.tight_layout()
plt.show()

"""## **ðŸ”µEDA Conclusions**

### **1. Date Range**  
- Period: **January 10, 2021 â€“ September 9, 2021**  
- ~9 months of user-level transactions  

---

### **13.0 Top Product Pairs by Transaction Volume**

* **Highly concentrated pattern:**   A few product pairs dominate the volume â€” the top pair exceeds **450 transactions**, far above the average.
* **Steep drop-off:**   After the first three to five pairs, volumes decline quickly, stabilising around **100â€“200 transactions** for the remaining top 50.
* **Low overall frequency:**  Descriptive statistics show the **average pair only appears ~19 times**, with a median of **14 transactions**, meaning most pairs occur rarely.
* **Main takeaway:**  Cross-selling activity is **heavily driven by a small number of high-performing pairs**,  
  while the majority of combinations contribute marginally and require strategic focus if they are to grow.


---

### **3.0 Distribution of Pair Transaction Counts**

* **Skewed pattern:**  The histogram shows a strong right skew â€” most product pairs occur only a few times, while only a few pairs appear very often.
* **Low typical frequency:**  The median is **14 transactions**, meaning more than half of all pairs occur fewer than 14 times.
* **Outliers visible:**  The boxplot highlights several pairs with very high counts (60â€“130 transactions), standing far away from the rest.
* **Overall takeaway:**  Most product pairs are low-frequency, and only a small group performs strongly in cross-selling activity.

---

### **3.1 Distribution of Average Pair Price**

* **Most pairs sit in a mid-price range:**  The median price is around **$32**, showing that typical product pairs fall in a moderate price segment.
* **Right-skewed distribution:**  The histogram shows a slight right skew â€” lower and mid-priced pairs are more common, while high-priced pairs occur less often.

* **Outliers exist at the high end:**  A few product pairs reach prices above **$75â€“$95**, which stand out clearly in the boxplot.

* **Overall takeaway:**  Cross-selling combinations are generally mid-priced, but there are a small number of premium pairings with significantly higher price levels.

---

### **3.2 Distribution of Total Sales per Pair**

* **Skewed distribution:**  The histogram shows a strong right skew â€” many pairs generate low to moderate sales, while only a few reach very high totals.
* **Central tendency is moderate:**  The median sales value is around **$2,276**, meaning half of all pairs generate less than this amount.
* **High variance and outliers:**  Several pairs reach **$10,000â€“$26,000**, clearly visible as outliers in the boxplot.
* **Overall takeaway:**   Most product pairs produce modest sales figures, but a small group of pairs drives a disproportionately high amount of revenue.

---

### **3.3 Distribution of Average Margin per Pair**

* **Margins cluster around a mid-level:**  The median margin is about **56%**, meaning most product pairs deliver a solid profit level.
* **Fairly concentrated spread:**  The histogram shows a relatively tight range, with many values between **48â€“63%**, indicating stable margin performance.
* **A few outliers exist:**  Some pairs fall below **25%**, while others reach **80%+**, visible as points outside the main boxplot area.
* **Overall takeaway:**   Most cross-selling pairs achieve healthy and consistent margins, with only a small number performing unusually low or unusually high.

---

### **3.4 Distribution of Total Profit per Pair**

* **Profit values are very uneven:**  
  The distribution is **strongly right-skewed**, meaning only a few pairs earn very high profit.

* **Most product pairs stay modest:**  
  The median profit of around **$1.2k** shows that typical pairs contribute moderate profit.

* **Some pairs generate exceptional profit:**  
  Outliers reach **$10kâ€“$20k**, visible at the top end of the boxplot.

* **Main takeaway:**  
  Cross-selling profit potential exists, but it is concentrated in a **small set of highly valuable product pairs**, while the majority perform at a much lower level.

---

### **3.5 & 3.6 Support Distribution for Products (A & B Combined)**

*Support A and Support B are interpreted together because they describe the same underlying concept â€”  
how frequently individual products appear in transactions.  
The distinction between A and B exists only due to pair structure, not because they represent different products.*

* **Low overall presence:**   Most products appear in only **5â€“12%** of transactions, indicating selective or niche buying patterns.
* **Wide variability:**  The spread is broad â€” while many products have low visibility, a smaller group reaches support levels above **15%**.
* **Few dominant products:**  Outliers exceed **20â€“25%**, reflecting a small set of highly purchased items.
* **Main takeaway:**   Product frequency in baskets is **uneven but consistently low** across the catalog.  
  This means cross-selling opportunities depend heavily on a **small group of high-exposure products**, while most items require strategic visibility to contribute.

---

### **3.7 Distribution of Pair Support**

* **Very low occurrence overall:**  Most product pairs appear in **less than 1% of transactions**, meaning true co-buying events are rare.
* **Strong skew toward zero:**  The histogram shows a heavy right-skew â€” the majority of pairs occur extremely infrequently, with only a few gaining notable visibility.
* **Outliers exist but remain small:**  Even the most frequently appearing pairs reach only **6% support**, far below product-level support values.
* **Main takeaway:**   Cross-selling relationships are **weak for most pairs** â€” only a small number of combinations repeatedly occur in the data.  
  This indicates **high fragmentation of demand** and highlights the importance of identifying the few strong co-purchase patterns.

---

### **3.8 Distribution of Confidence**

* **Generally weak association strength:**  
  Confidence values mostly fall between **6% and 16%**, indicating that product B is rarely purchased after product A.* **Highly skewed distribution:**  
  The histogram shows a heavy right-skew â€” most pairs exhibit low confidence, while only a few cases reach beyond **30â€“50%**.
* **Clear outliers:**  A small set of pairs achieves **>40% confidence**, suggesting strong directed buying relationships.
* **Main takeaway:**   Cross-sell dependencies are **weak for most product pairs**,  
  but a **very small group of pairs shows meaningful recommendation potential**.

---

### **11.0 Distribution of Lift**
* **Most relationships are only mildly positive:**  
  The central tendency lies just above **1.0**, meaning most pairs co-occur slightly more often than random chance.
* **Strong right-skew:**   The majority cluster between **0.8 and 1.5**, while a long tail stretches toward **very high Lift values**.
* **Rare but powerful associations:**  Outliers reaching **6â€“16Ã— expected frequency** indicate a small set of product pairs with exceptionally strong cross-sell behavior.
* **Main takeaway:**  Lift confirms that **true cross-selling strength exists â€” but only for very few combinations**.  
  For most pairs, the effect is weak to moderate, reinforcing the value of **focusing recommendations on top Lift performers**.

---

### **12.0 Cross-Sell Rate Over Time**

* **Stable behaviour overall:**  The quarterly cross-sell rate ranges narrowly between **34% and 46%**, indicating a steady level of paired purchasing.
* **Noticeable peak mid-period:**  The highest rate occurs in **Q2 2021 (~46%)**, suggesting a temporary rise in co-purchasing activity.
* **Minor softening afterwards:**  Following the peak, the rate settles slightly lower (~41â€“42%), but remains **above the starting level**.
* **Main takeaway:**  Cross-selling intensity is **consistently strong across periods**, with a **mid-period uplift** that may reflect marketing actions, seasonality, or demand shifts.

# ðŸŸ¦ **5. Dashboard**

The final dashboard presents the results of this cross-selling analysis in an interactive and business-friendly format.  
It allows users to explore performance trends, key metrics, and product pair insights directly.

ðŸ”— **Access the dashboard:**  
https://lookerstudio.google.com/reporting/8823545f-b537-4607-ae20-4a072a628276

> **Navigation tip:**  
After opening the dashboard, click **More options â†’ Present** to view it in full screen mode for a better experience.
"""